{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will be auditing and cleaning OpenStreetMap data for Santa Cruz County in California. During the course, we looked at OSM data for Chicago and found inconsistencies in street name abbreviations and postal codes. We will look for the same problems in the Santa Cruz data. After cleaning it up, we will rewrite the data as a JSON file and upload it to MongoDB. We can use MongoDB to write queries on the data. A view of the area can be seen at http://www.openstreetmap.org/relation/396473."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Auditing the Data\n",
    "\n",
    "##Phone Numbers\n",
    "Before starting with the problems from the case study, let's look at the data. If we run *auditing/auditKeys.py* we see that the node and way elements have 897 unique tag attribute keys. Cleaning all of these is beyond the scope of this project, but let's set out to clean the *phone* attributes. \n",
    "\n",
    "When running *auditing/auditPhone.py* we see that phone numbers are not written in a standard format. Some of the numbers have +1, or parentheses around the area code, or dashes throughout the number. We want all of the phone numbers to be in the 10-digit format *xxx-xxx-xxxx*. They will be updated using *processing/updatePhone.py* when we process the file into json format.\n",
    "\n",
    "##Street Name Abbreviations\n",
    "We don't want any abbreviated street names in our data. We expect the last word of each street name to be Street, Avenue, Road, etc. We'll parse through the street names in this set and create a dictionary of unexpected and abbreviated values using *auditing/auditStreetNames.py*.\n",
    "\n",
    "We have a lot of unexpected endings, 105 to be exact. Although not all of these are invalid. Some are correct endings that we just didn't initally think of, like Circle, Highway, and Terrace. There are a few Avenues, Roads, Drives, and Streets written as Ave, Rd, Dr, and St respectively. To make the data consistent, we want to chage Ave to Avenue, Rd to Road, etc. We also want to look up Cedar, Chestnut, Front, Merrill, Pacific, and Seabright on another map and see if they are Streets, Avenues, or Roads and change them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Postal Code Inconsistencies\n",
    "We now want to look at our set of postal codes. We can write a code similar to our street name audit to print the set of postal codes in our data. There is no need for a dictionary since we want to look at the full postal code entry. Instead we'll just create the set of all postal codes by running *auditing/auditPostcodes.py*.\n",
    "\n",
    "First thing we see is that the postcode field sometimes has full addresses, some of which are missing the actual postcode. Other entries contain the 9-digit postcode or the 5-digit postcode. Some are in the form *CA xxxxx*. Since the 5-digit form is the least common denominator, we will use regular expressions to find a 5-digit string that begins with a 9. If there is no string of this sort, the entry will be assigned *None* for its postcode. The code can be found in *processing/updatePostcode.py*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Converting OSM to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we upload the data to MongoDB, we have to rewrite it in JSON form. We only want to process top-level tags \"node\" and \"way\", turning their attributes in key/value pairs, except: \n",
    "- attributes in the CREATED array should be added under a key \"created\"\n",
    "- attributes for latitude and longitude should be added to a \"pos\" array,\n",
    "  for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n",
    "  and not strings. \n",
    "- if second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "- if second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "- if second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can process it\n",
    "  same as any other tag.\n",
    "- if there is a second \":\" that separates the type/direction of a street,\n",
    "  the tag should be ignored.\n",
    "- for \"way\" specifically, tags starting with \"nd ref\" should be added to array called \"node_refs\".\n",
    "\n",
    "We will also extend street name abbreviations and add Avenue or Street to the proper street names. Postal codes, aside from 1982, will be converted to a 5-digit form. We do this by running *auditing/processMap.py*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###A Note on id's\n",
    "\n",
    "\n",
    "When we upload our data into MongoDB, each entry will be assigned a unique id under '_id'. Our data already has an id field, but in order to use it we have to make sure that each 'id' is truely unique in our OSM file. If so, we'll have to match the id value to the '_id' key instead of a 'id' key. \n",
    "If we try to write code to check for uniqueness, we'll essentially have to compare over 250,000 lines against each other. This would take a ton of time to compute so instead I looked up how id's in OSM are created and found this: http://gis.stackexchange.com/questions/103572/are-osm-ids-unique-over-all-object-types. One user claims that OSM id's are composed of type of object, id, version, and combination of tags. Though it is highly unlikely, there is still a possibility that a node and way have the same id number. The larger the file, the more likely it is that we run into a problem. We'll let MongoDB assign unique numbers to the '_id' field.\n",
    "\n",
    "This completes auditing and cleaning the data for now. We can now upload the data to MongoDB and explore the data. If necessary, more cleaning can be done there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploring the Data\n",
    "\n",
    "We have uploaded the data as a collection santacruz into a database called maps. There are two options for looking at the data, either through the command line or with python using the pymongo library. Since we are working in an iPython Notebook we will use pymongo. The commands are very similar if not the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618670592.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient()\n",
    "db = client['maps']\n",
    "db.command(\"dbstats\")['dataSize']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the santacruz collection is just under 619 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Entry Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2141872\n",
      "\n",
      "Number of nodes: 1940560\n",
      "\n",
      "Number of ways: 201172\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "docs = db.santacruz.find().count()\n",
    "nodes = db.santacruz.find({'type':'node'}).count()\n",
    "ways = db.santacruz.find({'type':'way'}).count()\n",
    "\n",
    "print 'Number of documents:', docs\n",
    "print '\\nNumber of nodes:', nodes\n",
    "print '\\nNumber of ways:', ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 1310\n",
      "\n",
      "Top 10 contributing users\n",
      "{u'_id': u'nmixter', u'contributions': 687389}\n",
      "{u'_id': u'stevea', u'contributions': 300529}\n",
      "{u'_id': u'mk408', u'contributions': 208472}\n",
      "{u'_id': u'DanHomerick', u'contributions': 71515}\n",
      "{u'_id': u'Bike Mapper', u'contributions': 66034}\n",
      "{u'_id': u'woodpeck_fixbot', u'contributions': 55896}\n",
      "{u'_id': u'doug_sfba', u'contributions': 50953}\n",
      "{u'_id': u'karitotp', u'contributions': 46419}\n",
      "{u'_id': u'Alexander Avtanski', u'contributions': 42073}\n",
      "{u'_id': u'dannykath', u'contributions': 40964}\n"
     ]
    }
   ],
   "source": [
    "users = db.santacruz.distinct('created.user')\n",
    "\n",
    "top_users = db.santacruz.aggregate([\n",
    "        {'$group': {'_id':'$created.user', 'contributions':{'$sum':1}}},\n",
    "        {'$sort':{'contributions':-1}},\n",
    "        {'$limit':10}\n",
    "    ])\n",
    "\n",
    "print 'Unique users:', len(users)\n",
    "print '\\nTop 10 contributing users'\n",
    "for doc in top_users:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postal Codes\n",
      "{u'count': 15874, u'_id': u'95014'}\n",
      "{u'count': 753, u'_id': u'95037'}\n",
      "{u'count': 470, u'_id': u'95045'}\n",
      "{u'count': 425, u'_id': u'95064'}\n",
      "{u'count': 335, u'_id': u'95004'}\n",
      "{u'count': 236, u'_id': u'95070'}\n",
      "{u'count': 100, u'_id': u'95060'}\n",
      "{u'count': 92, u'_id': u'95125'}\n",
      "{u'count': 87, u'_id': u'95129'}\n",
      "{u'count': 74, u'_id': u'95135'}\n",
      "{u'count': 73, u'_id': u'95128'}\n",
      "{u'count': 59, u'_id': None}\n",
      "{u'count': 54, u'_id': u'95123'}\n",
      "{u'count': 49, u'_id': u'95008'}\n",
      "{u'count': 47, u'_id': u'95126'}\n"
     ]
    }
   ],
   "source": [
    "postcodes = db.santacruz.aggregate([\n",
    "        {'$match':{'address.postcode':{'$exists':1}}},\n",
    "        {'$group':{'_id':'$address.postcode', 'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':15}\n",
    "    ])\n",
    "\n",
    "print \"Postal Codes\"\n",
    "for doc in postcodes:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Street names\n",
      "{u'count': 348, u'_id': u'Stevens Creek Boulevard'}\n",
      "{u'count': 176, u'_id': u'McClellan Road'}\n",
      "{u'count': 147, u'_id': u'Rainbow Drive'}\n",
      "{u'count': 130, u'_id': u'South Stelling Road'}\n",
      "{u'count': 125, u'_id': u'Imperial Avenue'}\n",
      "{u'count': 123, u'_id': u'East Estates Drive'}\n",
      "{u'count': 120, u'_id': u'Johnson Avenue'}\n",
      "{u'count': 117, u'_id': u'Miller Avenue'}\n",
      "{u'count': 117, u'_id': u'Bollinger Road'}\n",
      "{u'count': 113, u'_id': u'Carr Avenue'}\n"
     ]
    }
   ],
   "source": [
    "streetnames = db.santacruz.aggregate([\n",
    "        {'$match':{'address.street':{'$exists':1}}},\n",
    "        {'$group':{'_id':'$address.street', 'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':10}\n",
    "    ])\n",
    "\n",
    "print \"Street names\"\n",
    "for doc in streetnames:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Amenities\n",
      "{u'count': 3036, u'_id': u'parking'}\n",
      "{u'count': 928, u'_id': u'restaurant'}\n",
      "{u'count': 617, u'_id': u'school'}\n",
      "{u'count': 532, u'_id': u'toilets'}\n",
      "{u'count': 521, u'_id': u'place_of_worship'}\n",
      "{u'count': 449, u'_id': u'bench'}\n",
      "{u'count': 438, u'_id': u'fast_food'}\n",
      "{u'count': 369, u'_id': u'bicycle_parking'}\n",
      "{u'count': 292, u'_id': u'cafe'}\n",
      "{u'count': 243, u'_id': u'fuel'}\n"
     ]
    }
   ],
   "source": [
    "amenity = db.santacruz.aggregate([\n",
    "        {'$match':{'amenity':{'$exists':1}}},\n",
    "        {'$group':{'_id':'$amenity', 'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':10}\n",
    "    ])\n",
    "\n",
    "print 'Top 10 Amenities'\n",
    "for doc in amenity:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular cuisine\n",
      "{u'count': 124, u'_id': u'mexican'}\n",
      "{u'count': 88, u'_id': u'pizza'}\n",
      "{u'count': 87, u'_id': u'vietnamese'}\n",
      "{u'count': 86, u'_id': u'burger'}\n",
      "{u'count': 79, u'_id': u'chinese'}\n",
      "\n",
      "Religions\n",
      "{u'count': 430, u'_id': u'christian'}\n",
      "{u'count': 12, u'_id': u'buddhist'}\n",
      "{u'count': 8, u'_id': u'jewish'}\n",
      "{u'count': 2, u'_id': u'unitarian_universalist'}\n",
      "{u'count': 1, u'_id': u'pagan'}\n",
      "\n",
      "Christian denominations\n",
      "{u'count': 42, u'_id': u'baptist'}\n",
      "{u'count': 33, u'_id': u'catholic'}\n",
      "{u'count': 23, u'_id': u'presbyterian'}\n",
      "{u'count': 21, u'_id': u'lutheran'}\n",
      "{u'count': 21, u'_id': u'methodist'}\n"
     ]
    }
   ],
   "source": [
    "cuisine = db.santacruz.aggregate([\n",
    "        {'$match':{'cuisine':{'$exists':1}}},\n",
    "        {'$group':{'_id':'$cuisine', 'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':5}\n",
    "    ])\n",
    "\n",
    "religion = db.santacruz.aggregate([\n",
    "        {'$match':{'religion':{'$exists':1}}},\n",
    "        {'$group':{'_id':'$religion', 'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':5}\n",
    "    ])\n",
    "\n",
    "denomination = db.santacruz.aggregate([\n",
    "        {'$match':{'religion':'christian','denomination':{'$exists':1}}},\n",
    "        {'$group':{'_id':'$denomination', 'count':{'$sum':1}}},\n",
    "        {'$sort':{'count':-1}},\n",
    "        {'$limit':5}\n",
    "    ])\n",
    "\n",
    "print 'Most popular cuisine'\n",
    "for doc in cuisine:\n",
    "    print doc\n",
    "    \n",
    "print '\\nReligions'\n",
    "for doc in religion:\n",
    "    print doc\n",
    "    \n",
    "print '\\nChristian denominations'\n",
    "for doc in denomination:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing the problems that we've encountered and due to the fact that there are over 1300 users contributing to the data, I imagine there is a lot more to audit. Running *auditing/auditAmenities*, we see that the amenities could be cleaned up by grouping similar types. For example, bar and pub represent the same type, as does coffee and cafe. We would need to think of a systematic way of fixing this, though I think the only choice would be to go in and manually group similar type.\n",
    "\n",
    "Adding postal codes to addresses can be quite challenging. My first thought was to use street names to add postal codes, but some streets span multiple cities or multiple postal codes within a single city. Alternatively, we could look up a US postal code database and try to write code to match some entries.\n",
    "\n",
    "We will always need to audit and clean our data, but the process can be made easier if we have accurate user input. I suggest that anyone interested in inputing or cleaning OSM data for Santa Cruz to get in touch with users in the area. It sounds like a fun project to take on as a hobby!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
